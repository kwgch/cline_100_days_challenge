## プロジェクト仕様書: ブラウザ版 日本語GPT-2 文章生成 & 次トークン確率可視化ツール

### 1. 目的

本アプリケーションは、Webブラウザ上で日本語GPT-2モデル（`rinna/japanese-gpt2-medium` の量子化ONNX版）を実行し、ユーザーが入力したテキストに続く文章を生成する。同時に、文章生成の各ステップにおいて、モデルが次に予測する可能性が高いトークン（単語や文字の一部）とその確率を表示することで、モデルの内部的な予測プロセスの一部を可視化することを目的とする。

### 2. 対象ユーザー

*   ブラウザ上で動作する自然言語生成モデルのデモンストレーションに関心のあるユーザー。
*   GPT-2モデルがどのように次の単語を予測しているか、その確率分布に興味のある開発者や学生。

### 3. 主要機能

1.  **テキスト入力**: ユーザーが文章生成の開始点となる日本語テキストを入力できるテキストエリアを提供する。
2.  **最大生成長設定**: ユーザーが生成する文章の最大トークン数を指定できる数値入力フィールドを提供する。
3.  **モデル読み込み**: ページ読み込み時に、ローカルに配置された量子化ONNXモデルと対応するトークナイザーを非同期で読み込む。
    *   読み込み中はステータス表示エリアに進捗（ファイル名とパーセンテージ）を表示する。
4.  **文章生成実行**:
    *   「文章を生成」ボタンをクリックすると、入力テキストと最大生成長設定に基づいて文章生成処理を開始する。
    *   処理中はボタンを無効化し、「生成中...」インジケーターを表示する。
5.  **生成結果表示**: 生成された文章を指定されたエリアに表示する。生成中は部分的な結果を逐次表示する。
6.  **次トークン予測確率表示**: 文章生成の各ステップにおいて、モデルが予測する次のトークンの確率分布を計算し、確率の高い上位5件のトークンとその確率を指定されたエリアにリスト形式で表示する。
7.  **ステータス表示**: モデルの読み込み状況、生成中の状態、処理完了、エラー発生などの状態を画面上部のステータスエリアに表示する。

### 4. 技術スタック

*   **フロントエンド**: HTML, CSS, JavaScript
*   **MLライブラリ**: Transformers.js (@xenova/transformers) - ONNX Runtime Web (WASM/WebGL) バックエンドを利用
*   **モデル**: 量子化された `rinna/japanese-gpt2-medium` ONNXモデルと関連ファイル (ユーザーがローカルに配置)

### 5. 非機能要件

*   **実行環境**: モダンなWebブラウザ（Chrome, Firefox, Edgeなど）で動作すること。
*   **セットアップ**: 事前に量子化ONNXモデルファイル一式を準備し、HTMLファイルと同じ階層または指定されたパス (`./onnx_model_quantized/`) に配置する必要がある。アプリケーションの実行にはローカルHTTPサーバーが必要となる。
*   **パフォーマンス**: 量子化モデルを使用することで、非量子化モデルよりも少ないメモリで動作する。ただし、生成長やブラウザ環境によっては応答性が低下する可能性がある。
*   **UI/UX**: シンプルなインターフェースで、入力、実行、結果確認が容易に行える。
